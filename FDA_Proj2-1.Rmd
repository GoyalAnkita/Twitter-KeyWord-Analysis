---
title: "proj2"
author: "Group 17"
date: "03/12/2021"
output: html_document
---
#Task 1
```{r}

#loading dataset
library(dplyr)
library(stringr)
library(tidytext)
library(ggplot2)
library(tidyr)
library(igraph)
library(ggraph)
library(plotly)

```

```{r}
keyword_data <- read.csv("Keyword_data - Keyword_data.csv")

#creating an adjecency matrix

#removing the empty spaces from the data set and title
keyword_data<-keyword_data[(keyword_data$Keyword.1!=""),-1]

#identifying unique values
keyword=unique(keyword_data[1])

#renaming the column value
colnames(keyword)<-c('keyword_value')

#binding all the keyword into one column
for( i in 2:length(keyword_data))
{ 
  temp<-keyword_data[i]
  colnames(temp)<-c('keyword_value')
  temp<-temp %>% filter(keyword_value!="")
  keyword<-rbind(keyword,temp)
  
}
# after binding- get only the unique keywords
keyword <- unique(keyword)

#creating a data frame for the keyword match
df<-data.frame(matrix(0,nrow=count(keyword)[[1]],ncol = count(keyword)[[1]]))
colnames(df)<-keyword$keyword_value ->rownames(df)

#------------------------------------------------------------
len_of_keyword_data <- dim(keyword_data)[1]

for(article in 1:len_of_keyword_data) # traversing through the article- index position
{ 
  len<-length(keyword_data[article,]) # calculating the length of each article
  for(kw_one in 1:(len-1)) # kw_one-- keyword one 
  {
    for(kw_two in (kw_one+1):len) #kw_two--- keyword two
    {
      if(keyword_data[article,kw_one]!='' & keyword_data[article,kw_two]!='')
      { 
        df[keyword_data[article,kw_one],keyword_data[article,kw_two]]<-as.integer(df[keyword_data[article,kw_one],keyword_data[article,kw_two]]+1) -> df[keyword_data[article,kw_two],keyword_data[article,kw_one]]
      }
    }
    
  }
}

sum(df)
View(df)
```


```{r}

df2<- data.matrix(df)
net1<-graph_from_adjacency_matrix(df2,mode="undirected", weighted = T)

```

```{r}
#plot(net1)

```

```{r}
# Degree of network
deg <- degree(net1, mode="all")
# Strength of network
strength <- strength(net1, mode="all")


```


```{r}
top_10_degree<- data.frame(head(sort(deg, decreasing = T), 10))
top_10_strength<- data.frame(head(sort(strength, decreasing = T), 10))

```

```{r}
top_10_degree
```

```{r}
top_10_strength
```
```{r}
node_pair_weights <- get.data.frame(net1)

```

```{r}
node_pair_top10<-head(node_pair_weights[order(node_pair_weights$weight, decreasing = T),],10)
#top_10_node_pair_weights<- data.frame(head(sort(node_pair_weights$weight, decreasing = T), 10))

```

```{r}
show(node_pair_top10)
```

```{r}
library(dplyr)
library(plotly)

df<- data.frame(deg,strength)
grouped<- df %>% group_by(deg) %>% summarise(avg_strength=mean(strength))

fig<-plot_ly(grouped,x=~deg,y=~avg_strength,marker=list(size=5))
fig <- fig %>% layout(title = 'Degree V/S Avg Strength' )
fig
```

#Tast 2
```{r}
#install.packages('tm')
#install.packages('tidyverse')
#install.packages('lubridate')
library(tm)
library(lubridate)
df <- read.csv("2021.csv", header = T)
df$year<-year(as.POSIXct(df$date, format = "%Y-%m-%d %H:%M:%S"))
df<-df %>% filter(year>=2017)
```

```{r}
#cleaning the data

word_unnest <-df %>% select(year,tweet) %>%  unnest_tokens(word,tweet)
# removing the special characters that are attached in the word
word_unnest$word <- (str_replace_all(word_unnest$word, "[^a-zA-Z0-9./'-]", ""))
word_unnest$word <- (str_replace_all(word_unnest$word, " ", ""))
#removing stop words and counting the word occurrence on each year
word_count <- word_unnest %>% filter(word != '' )%>% 
               anti_join(stop_words, by= c("word" = "word"))%>% count(year, word, sort = TRUE)
```

```{r}
#counting number of words on each year
total_words <- word_count %>% group_by(year) %>% summarize(total = sum(n))
#joining the total word count with the word_Count dataset
word_count <- left_join(word_count, total_words)
# top 10 word based on the count of occurences on each year
a<-word_count %>% group_by(year) %>% slice(1:10)
ggplot(word_count, aes(n/total, fill = as.character(year))) +
  geom_histogram(show.legend = FALSE) +
  xlim(NA, 0.009) +
  facet_wrap(~year, ncol = 2, scales = "free_y")

```

#zipf's law
```{r}
#finding rank and frequency of each word
freq_by_rank <- word_count %>% mutate(year=as.character(year)) %>% 
  group_by(year) %>% 
  mutate(rank = row_number(), 
         `term frequency` = n/total) %>%
  ungroup()

#subsetting the dataset
rank_subset <- freq_by_rank %>% 
   filter(rank < 500,
          rank > 10)

#finding intercept and slope for linear model
lm(log10(`term frequency`) ~ log10(rank), data = rank_subset)

#plotting of linear model
rank_subset %>% 
  ggplot(aes(rank, `term frequency`, color = year)) + 
  geom_abline(intercept = -1.7467 , slope = -0.6202, 
              color = "gray50", linetype = 2) +
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
  scale_x_log10() +
  scale_y_log10()

```

#bigram network
```{r}
bigram <- df %>% select(year,tweet) %>% unnest_tokens(bigram, tweet, token = "ngrams", n = 2)
# cleaning of the data
bigrams_separated <- bigram %>%
  separate(bigram, c("word1", "word2"), sep = " ")
bigrams_separated<-bigrams_separated %>% filter(!substr(word1,1,1) == "0")
bigrams_separated<-bigrams_separated %>% filter(!substr(word2,1,1) == "0")
bigrams_separated$word1 <- (str_replace_all(bigrams_separated$word1, "[^a-zA-Z0-9./,-]", ""))
bigrams_separated$word2 <- (str_replace_all(bigrams_separated$word2, "[^a-zA-Z0-9./,-]", ""))
bigrams_separated<-bigrams_separated %>%  drop_na()
bigrams_filtered <- bigrams_separated %>% filter(word1!=''& word2!='') %>% 
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

```

#for year 2017
```{r}
#yr=yr+1
bigram_counts <- bigrams_filtered %>% filter(year==2017) %>% filter(word1!=''& word2!='') %>% 
  count(word1, word2, sort = TRUE)


bigram_graph <- bigram_counts %>%
  filter(n > 2) %>%
  graph_from_data_frame()

set.seed(2020)

a <- grid::arrow(type = "closed", length = unit(.05,"inches"))

ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(0.05, 'inches')) +
  geom_node_point(color = "lightblue", size = 2) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void()

```
#for year 2018
```{r}
bigram_counts <- bigrams_filtered %>% filter(year==2018) %>% filter(word1!=''& word2!='') %>% 
  count(word1, word2, sort = TRUE)


bigram_graph <- bigram_counts %>%
  filter(n > 6) %>%
  graph_from_data_frame()

set.seed(2020)

a <- grid::arrow(type = "closed", length = unit(.05,"inches"))

ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(0.05, 'inches')) +
  geom_node_point(color = "lightblue", size = 2) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void()

```
#for year 2019
```{r}
#yr=yr+1
bigram_counts <- bigrams_filtered %>% filter(year==2019) %>% filter(word1!=''& word2!='') %>% 
  count(word1, word2, sort = TRUE)


bigram_graph <- bigram_counts %>%
  filter(n > 9) %>%
  graph_from_data_frame()

set.seed(2020)

a <- grid::arrow(type = "closed", length = unit(.05,"inches"))

ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(0.05, 'inches')) +
  geom_node_point(color = "lightblue", size = 2) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void()

```
#for year 2020
```{r}
#yr=yr+1
bigram_counts <- bigrams_filtered %>% filter(year==2020) %>% filter(word1!=''& word2!='') %>% 
  count(word1, word2, sort = TRUE)


bigram_graph <- bigram_counts %>%
  filter(n > 11) %>%
  graph_from_data_frame()

set.seed(2020)

a <- grid::arrow(type = "closed", length = unit(.05,"inches"))

ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(0.05, 'inches')) +
  geom_node_point(color = "lightblue", size = 2) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void()

```
#for year 2021
```{r}
#yr=yr+1
bigram_counts <- bigrams_filtered %>% filter(year==2021) %>% filter(word1!=''& word2!='') %>% 
  count(word1, word2, sort = TRUE)


bigram_graph <- bigram_counts %>%
  filter(n > 2) %>%
  graph_from_data_frame()

set.seed(2020)

a <- grid::arrow(type = "closed", length = unit(.05,"inches"))

ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(0.05, 'inches')) +
  geom_node_point(color = "lightblue", size = 2) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void()

```

